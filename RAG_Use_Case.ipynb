{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7f82e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function dotenv.main.load_dotenv(dotenv_path: Union[str, ForwardRef('os.PathLike[str]'), NoneType] = None, stream: Optional[IO[str]] = None, verbose: bool = False, override: bool = False, interpolate: bool = True, encoding: Optional[str] = 'utf-8') -> bool>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ad7e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required LangChain modules\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7f89845b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define LLM to be used\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-pro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5193e1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate LLMs\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "#llm=ChatGroq(model_name=\"Gemma2-9b-It\")\n",
    "\n",
    "#llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edac1542",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91852\\Documents\\Machine Learning\\Gen AI\\AI_Agents\\env_langchain\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Define the Embeddings model\n",
    "\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66061920",
   "metadata": {},
   "source": [
    "Step 1 - Document Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "275e6b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read the Script\n",
    "\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "loader = PyMuPDFLoader('Scripts/Dummy_Script.pdf')\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b1b990",
   "metadata": {},
   "source": [
    "Step 2 - Document Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c3cade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the document and create Chunks\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 200)\n",
    "chunks = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133611ee",
   "metadata": {},
   "source": [
    "Step 3 - Indexing (Embedding Generation and Storing in Vector Store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f19e1105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Vector Store\n",
    "\n",
    "vector_store = FAISS.from_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b36c520",
   "metadata": {},
   "source": [
    "Step 4 - Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77a7262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Retriever\n",
    "\n",
    "retriever = vector_store.as_retriever(search_type = 'similarity', search_kwargs={'k':4})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ff1438",
   "metadata": {},
   "source": [
    "Step 5 - Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ca1e949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Prompt Template\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "      You are a SAS code reviewer focussing on Data Lineage.\n",
    "      Answer ONLY from the provided transcript context.\n",
    "      Give your answer in 2 -3 sentences.\n",
    "      If the context is insufficient, just say you don't know.\n",
    "\n",
    "      {context}\n",
    "      Question: {question}\n",
    "    \"\"\",\n",
    "    input_variables = ['context', 'question']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f77273ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The source table for the `processed.customer_orders_raw` dataset is `rawdata.orders`. The `processed.final_customer_data` dataset is merged from `processed.customer_sales_summary` and `rawdata.customer_demographics`.\n"
     ]
    }
   ],
   "source": [
    "# Test the Prompt\n",
    "\n",
    "question          = \"What is the source table?\"\n",
    "retrieved_docs    = retriever.invoke(question)\n",
    "\n",
    "context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "final_prompt = prompt.invoke({\"context\": context_text, \"question\": question})\n",
    "\n",
    "answer = llm.invoke(final_prompt)\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa25e736",
   "metadata": {},
   "source": [
    "Step 6 - Building a Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae7ef9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough, RunnableLambda\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f8aa8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(retrieved_docs):\n",
    "    context_text = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "    return context_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad6e1701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel Chain\n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    'context': retriever | RunnableLambda(format_docs),\n",
    "    'question': RunnablePassthrough()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9dfba0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Chain\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "main_chain = parallel_chain | prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6683401",
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = \"What child tables are created from the table 'customer_orders_filtered' ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac609727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided code, the table `processed.customer_sales_summary` is created from `processed.customer_orders_filtered`. This child table is the result of a `proc sql` step that aggregates sales and counts orders by customer.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_chain.invoke(question1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "752a9670",
   "metadata": {},
   "outputs": [],
   "source": [
    "question2 = \"What all will break if 'customer_orders_filtered' is deleted ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54905425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'If `processed.customer_orders_filtered` is deleted, the `proc sql` step that creates `processed.customer_sales_summary` will fail. This is because `processed.customer_sales_summary` directly uses `processed.customer_orders_filtered` as its input table. Consequently, the subsequent `data processed.final_customer_data` step would also break as it relies on `processed.customer_sales_summary` for its data.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_chain.invoke(question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7768762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question3 = \"What will break if column 'quantity' is deleted from the table 'orders' ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e300c105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"If the 'Quantity' column is deleted from the `rawdata.orders` table, the `OrderValue` variable in the `processed.customer_orders_raw` dataset will break. This is because `OrderValue` is calculated as `Quantity * UnitPrice`.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_chain.invoke(question3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b88d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
